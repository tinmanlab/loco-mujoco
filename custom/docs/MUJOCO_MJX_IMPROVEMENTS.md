# MuJoCo/MJX ê¸°ë°˜ Robustness í–¥ìƒ ë°©ì•ˆ

Isaac Gym ëŒ€ì‹  **MuJoCo/MJX**ë¡œ ìµœì‹  ê¸°ë²• êµ¬í˜„í•˜ê¸°

---

## ğŸ¯ ì™œ MuJoCo/MJXì¸ê°€?

### âœ… ì¥ì 
- **ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤** - Apache 2.0 ë¼ì´ì„¼ìŠ¤
- **ì ‘ê·¼ì„± ìš°ìˆ˜** - NVIDIA GPU ì¢…ì† ì—†ìŒ
- **JAX ê¸°ë°˜** - ìë™ ë¯¸ë¶„, GPU ë³‘ë ¬í™”, JIT ì»´íŒŒì¼
- **LocoMuJoCo í™œìš©** - 22,000+ mocap, ë‹¤ì–‘í•œ ë¡œë´‡ ëª¨ë¸
- **ìµœì‹  ì—°êµ¬ ì§€ì›** - ASE, PHC ë“± ëŒ€ë¶€ë¶„ MuJoCo ê¸°ë°˜

### âš ï¸ Isaac Gymê³¼ ë¹„êµ
| íŠ¹ì§• | Isaac Gym | MuJoCo/MJX |
|------|-----------|------------|
| ë¼ì´ì„¼ìŠ¤ | ì œí•œì  (NVIDIA) | ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤ |
| GPU ë³‘ë ¬í™” | âœ… | âœ… (ìš°ë¦¬ê°€ 4096 envs ì‚¬ìš© ì¤‘!) |
| ì ‘ê·¼ì„± | ì œí•œì  | ìš°ìˆ˜ |
| ì»¤ë®¤ë‹ˆí‹° | NVIDIA ì¤‘ì‹¬ | ê´‘ë²”ìœ„ |
| ë¬¼ë¦¬ ì—”ì§„ | PhysX | MuJoCo (ë” ì •í™•) |

---

## ğŸš€ MJX ê¸°ë°˜ Perturbation Training êµ¬í˜„

### 1. **External Force Perturbation Wrapper**

LocoMuJoCo í™˜ê²½ì— ì§ì ‘ ì ìš© ê°€ëŠ¥í•œ wrapper:

```python
# custom/wrappers/perturbation_wrapper.py

import jax
import jax.numpy as jnp
from functools import partial


class PerturbationWrapper:
    """
    MJX í™˜ê²½ì— ëœë¤ ì™¸ë ¥ì„ ì ìš©í•˜ëŠ” Wrapper
    Isaac Gymì˜ force perturbationê³¼ ë™ì¼í•œ ê¸°ëŠ¥
    """

    def __init__(self, env, config):
        self.env = env
        self.force_range = config.get('force_range', 100.0)  # N
        self.force_prob = config.get('force_prob', 0.1)
        self.force_duration = config.get('force_duration', 10)  # steps
        self.apply_to_bodies = config.get('bodies', ['pelvis', 'torso'])

    def reset(self, rng):
        obs, env_state = self.env.reset(rng)
        # ì´ˆê¸°í™” ì‹œ force ìƒíƒœ ì¶”ê°€
        env_state = env_state.replace(
            force_counter=jnp.zeros(self.env.num_envs),
            force_vec=jnp.zeros((self.env.num_envs, 3)),
            force_body_id=jnp.zeros(self.env.num_envs, dtype=jnp.int32)
        )
        return obs, env_state

    @partial(jax.jit, static_argnums=(0,))
    def step(self, env_state, action, rng):
        """
        ë§¤ stepë§ˆë‹¤:
        1. í™•ë¥ ì ìœ¼ë¡œ ìƒˆë¡œìš´ ì™¸ë ¥ ìƒì„±
        2. ì§€ì† ì‹œê°„ ë™ì•ˆ ì™¸ë ¥ ìœ ì§€
        3. í™˜ê²½ì— ì™¸ë ¥ ì ìš© í›„ step
        """
        rng, force_rng, body_rng = jax.random.split(rng, 3)

        # ìƒˆ ì™¸ë ¥ ìƒì„± ì—¬ë¶€ ê²°ì •
        should_apply_new_force = jax.random.bernoulli(
            force_rng, self.force_prob, shape=(self.env.num_envs,)
        )

        # force_counterê°€ 0ì´ë©´ ìƒˆ ì™¸ë ¥ ì ìš© ê°€ëŠ¥
        can_apply = env_state.force_counter == 0
        apply_new = jnp.logical_and(should_apply_new_force, can_apply)

        # ìƒˆ ì™¸ë ¥ ìƒì„± (ê· ë“± ë¶„í¬)
        new_force = jax.random.uniform(
            force_rng,
            shape=(self.env.num_envs, 3),
            minval=-self.force_range,
            maxval=self.force_range
        )

        # ëœë¤ body ì„ íƒ
        new_body_id = jax.random.randint(
            body_rng,
            shape=(self.env.num_envs,),
            minval=0,
            maxval=len(self.apply_to_bodies)
        )

        # ì™¸ë ¥ ì—…ë°ì´íŠ¸
        force_vec = jnp.where(
            apply_new[:, None],
            new_force,
            env_state.force_vec
        )

        force_body_id = jnp.where(
            apply_new,
            new_body_id,
            env_state.force_body_id
        )

        force_counter = jnp.where(
            apply_new,
            self.force_duration,
            jnp.maximum(env_state.force_counter - 1, 0)
        )

        # MuJoCo dataì— ì™¸ë ¥ ì ìš©
        # xfrc_applied shape: (nbody, 6) - [force_x, force_y, force_z, torque_x, torque_y, torque_z]
        data = env_state.data

        # Vectorized force application
        def apply_force_to_env(i, force, body_id):
            # ië²ˆì§¸ í™˜ê²½ì˜ body_idì— force ì ìš©
            xfrc = data.xfrc_applied[i].at[body_id, :3].set(force)
            return xfrc

        # ëª¨ë“  í™˜ê²½ì— ì™¸ë ¥ ì ìš©
        xfrc_applied = jax.vmap(apply_force_to_env)(
            jnp.arange(self.env.num_envs),
            force_vec,
            force_body_id
        )

        data = data.replace(xfrc_applied=xfrc_applied)
        env_state = env_state.replace(
            data=data,
            force_counter=force_counter,
            force_vec=force_vec,
            force_body_id=force_body_id
        )

        # í™˜ê²½ step
        obs, reward, done, info, env_state = self.env.step(env_state, action)

        return obs, reward, done, info, env_state
```

### 2. **Domain Randomization Wrapper**

ë¬¼ë¦¬ íŒŒë¼ë¯¸í„° ëœë¤í™” (Isaac Gymì˜ DRê³¼ ë™ì¼):

```python
# custom/wrappers/domain_randomization.py

import jax
import jax.numpy as jnp
from functools import partial


class DomainRandomizationWrapper:
    """
    MJX í™˜ê²½ì˜ ë¬¼ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ëœë¤í™”
    - ì§ˆëŸ‰ (mass)
    - ë§ˆì°°ë ¥ (friction)
    - ëŒí•‘ (damping)
    - ì•¡ì¶”ì—ì´í„° ê°•ë„ (actuator gain)
    """

    def __init__(self, env, config):
        self.env = env

        # Randomization ranges (percentage)
        self.mass_range = config.get('mass_range', 0.2)  # Â±20%
        self.friction_range = config.get('friction_range', 0.3)  # Â±30%
        self.damping_range = config.get('damping_range', 0.2)  # Â±20%
        self.actuator_range = config.get('actuator_range', 0.1)  # Â±10%

    @partial(jax.jit, static_argnums=(0,))
    def randomize_physics(self, model, rng):
        """
        ë§¤ episode reset ì‹œ ë¬¼ë¦¬ íŒŒë¼ë¯¸í„° ëœë¤í™”
        """
        rng, mass_rng, fric_rng, damp_rng, act_rng = jax.random.split(rng, 5)

        # 1. Mass randomization
        mass_scale = jax.random.uniform(
            mass_rng,
            shape=(model.nbody,),
            minval=1.0 - self.mass_range,
            maxval=1.0 + self.mass_range
        )
        new_mass = model.body_mass * mass_scale

        # 2. Friction randomization
        friction_scale = jax.random.uniform(
            fric_rng,
            shape=(model.ngeom, 3),
            minval=1.0 - self.friction_range,
            maxval=1.0 + self.friction_range
        )
        new_friction = model.geom_friction * friction_scale

        # 3. Damping randomization
        damping_scale = jax.random.uniform(
            damp_rng,
            shape=(model.njnt,),
            minval=1.0 - self.damping_range,
            maxval=1.0 + self.damping_range
        )
        new_damping = model.dof_damping * damping_scale

        # 4. Actuator gain randomization
        actuator_scale = jax.random.uniform(
            act_rng,
            shape=(model.nu,),
            minval=1.0 - self.actuator_range,
            maxval=1.0 + self.actuator_range
        )
        new_actuator_gain = model.actuator_gainprm[:, 0] * actuator_scale

        # Update model
        model = model.replace(
            body_mass=new_mass,
            geom_friction=new_friction,
            dof_damping=new_damping,
            actuator_gainprm=model.actuator_gainprm.at[:, 0].set(new_actuator_gain)
        )

        return model, rng

    def reset(self, rng):
        rng, reset_rng, rand_rng = jax.random.split(rng, 3)

        # ë¬¼ë¦¬ íŒŒë¼ë¯¸í„° ëœë¤í™”
        model, _ = self.randomize_physics(self.env.model, rand_rng)
        self.env.model = model

        # í™˜ê²½ ë¦¬ì…‹
        obs, env_state = self.env.reset(reset_rng)

        return obs, env_state
```

### 3. **Observation Noise Wrapper**

ì„¼ì„œ ë…¸ì´ì¦ˆ ì¶”ê°€ (sim-to-real gap ê°ì†Œ):

```python
# custom/wrappers/observation_noise.py

import jax
import jax.numpy as jnp
from functools import partial


class ObservationNoiseWrapper:
    """
    ê´€ì¸¡ê°’ì— ë…¸ì´ì¦ˆ ì¶”ê°€
    - ìœ„ì¹˜/ì†ë„ ì„¼ì„œ ë…¸ì´ì¦ˆ
    - IMU ë…¸ì´ì¦ˆ
    - ì§€ì—°(latency) ì‹œë®¬ë ˆì´ì…˜
    """

    def __init__(self, env, config):
        self.env = env

        self.position_noise = config.get('position_noise', 0.01)
        self.velocity_noise = config.get('velocity_noise', 0.1)
        self.imu_noise = config.get('imu_noise', 0.05)
        self.latency_steps = config.get('latency_steps', 2)  # ~40ms @ 50Hz

    @partial(jax.jit, static_argnums=(0,))
    def add_noise(self, obs, rng):
        """
        ê´€ì¸¡ê°’ì— ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
        """
        rng, noise_rng = jax.random.split(rng)

        noise = jax.random.normal(noise_rng, shape=obs.shape)

        # ìœ„ì¹˜/ì†ë„ êµ¬ë¶„í•˜ì—¬ ë‹¤ë¥¸ ë…¸ì´ì¦ˆ ë ˆë²¨ ì ìš©
        # (í™˜ê²½ë§ˆë‹¤ obs êµ¬ì¡°ê°€ ë‹¤ë¥´ë¯€ë¡œ ì¡°ì • í•„ìš”)
        noisy_obs = obs + noise * self.velocity_noise

        return noisy_obs, rng

    def step(self, env_state, action, rng):
        obs, reward, done, info, env_state = self.env.step(env_state, action)

        # ë…¸ì´ì¦ˆ ì¶”ê°€
        noisy_obs, rng = self.add_noise(obs, rng)

        return noisy_obs, reward, done, info, env_state
```

---

## ğŸ“‹ ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ

### Configuration (conf.yaml)

```yaml
# custom/training/unitreeh1_robust/conf.yaml

defaults:
  - override hydra/job_logging: default
  - override hydra/launcher: basic

wandb:
  project: "unitreeh1_robust_amp"

experiment:
  task_factory:
    name: ImitationFactory
    params:
      default_dataset_conf:
          task: [walk, run, pace]  # ë‹¤ì–‘í•œ ë™ì‘ í•™ìŠµ
      wrappers:
        - name: PerturbationWrapper
          params:
            force_range: 100.0      # ìµœëŒ€ 100N ì™¸ë ¥
            force_prob: 0.15        # 15% í™•ë¥ ë¡œ ì ìš©
            force_duration: 10      # 10 steps ì§€ì†
            bodies: [pelvis, torso, left_thigh, right_thigh]

        - name: DomainRandomizationWrapper
          params:
            mass_range: 0.2         # Â±20% ì§ˆëŸ‰ ë³€í™”
            friction_range: 0.3     # Â±30% ë§ˆì°° ë³€í™”
            damping_range: 0.2      # Â±20% ëŒí•‘ ë³€í™”
            actuator_range: 0.1     # Â±10% ì•¡ì¶”ì—ì´í„° ë³€í™”

        - name: ObservationNoiseWrapper
          params:
            position_noise: 0.01
            velocity_noise: 0.1
            imu_noise: 0.05
            latency_steps: 2

  env_params:
    env_name: MjxUnitreeH1
    headless: True
    horizon: 1000
    goal_type: GoalTrajRootVelocity
    goal_params:
      visualize_goal: false
    reward_type: TargetVelocityTrajReward

  # AMP ì„¤ì •
  hidden_layers: [512, 256, 256]  # ë” í° ë„¤íŠ¸ì›Œí¬
  lr: 5e-5                        # ì•½ê°„ ë‚®ì€ lr (ì•ˆì •ì„±)
  disc_lr: 4e-5
  num_envs: 4096                  # RTX 3070 ìµœì 
  num_steps: 14
  total_timesteps: 200e6          # 200M (ë” ê¸´ í•™ìŠµ!)
  update_epochs: 4
  disc_minibatch_size: 4096
  proportion_env_reward: 0.5
  n_disc_epochs: 50
  num_minibatches: 32
  gamma: 0.99
  gae_lambda: 0.95
  clip_eps: 0.1
  init_std: 0.2
  learnable_std: false
  ent_coef: 0.0
  disc_ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.75
  activation: tanh
  anneal_lr: false
  weight_decay: 0.0001
  normalize_env: true
  debug: false
  n_seeds: 1
  vmap_across_seeds: true
  validation:
    active: true
    num_steps: 1000
    num_envs: 100
    num: 10
```

### Training Script

```python
# custom/training/unitreeh1_robust/train.py

import os
import jax
from loco_mujoco import TaskFactory
from loco_mujoco.algorithms import AMPJax
import hydra
from omegaconf import DictConfig

# Custom wrappers
from custom.wrappers.perturbation_wrapper import PerturbationWrapper
from custom.wrappers.domain_randomization import DomainRandomizationWrapper
from custom.wrappers.observation_noise import ObservationNoiseWrapper


@hydra.main(version_base=None, config_path="./", config_name="conf")
def train(config: DictConfig):

    os.environ['XLA_FLAGS'] = '--xla_gpu_triton_gemm_any=True'

    # Create base environment
    factory = TaskFactory.get_factory_cls(config.experiment.task_factory.name)
    env = factory.make(**config.experiment.env_params,
                      **config.experiment.task_factory.params)

    # Apply wrappers
    for wrapper_conf in config.experiment.task_factory.wrappers:
        wrapper_class = globals()[wrapper_conf.name]
        env = wrapper_class(env, wrapper_conf.params)

    print(f"âœ“ Environment created with {len(config.experiment.task_factory.wrappers)} wrappers")
    print(f"  - Base: {config.experiment.env_params.env_name}")
    print(f"  - Wrappers: {[w.name for w in config.experiment.task_factory.wrappers]}")

    # Create expert dataset
    expert_dataset = env.create_dataset()

    # Initialize AMP agent
    agent_conf = AMPJax.init_agent_conf(env, config)
    agent_conf = agent_conf.add_expert_dataset(expert_dataset)

    # Build and JIT training function
    train_fn = AMPJax.build_train_fn(env, agent_conf)
    train_fn = jax.jit(train_fn)

    # Train
    print(f"\n{'='*80}")
    print(f"Starting Robust AMP Training")
    print(f"  - Total timesteps: {config.experiment.total_timesteps:,}")
    print(f"  - Parallel envs: {config.experiment.num_envs}")
    print(f"  - Perturbation: âœ…")
    print(f"  - Domain Randomization: âœ…")
    print(f"  - Observation Noise: âœ…")
    print(f"{'='*80}\n")

    rng = jax.random.PRNGKey(0)
    out = train_fn(rng)

    # Save agent
    result_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir
    save_path = AMPJax.save_agent(result_dir, agent_conf, out["agent_state"])

    print(f"\nâœ“ Training completed!")
    print(f"  Model saved: {save_path}")

    return out


if __name__ == "__main__":
    train()
```

---

## ğŸ“ ì¶”ê°€ ê³ ê¸‰ ê¸°ë²• (MuJoCo/MJX ê¸°ë°˜)

### 1. **Curriculum Learning**

ì ì§„ì ìœ¼ë¡œ ë‚œì´ë„ ì¦ê°€:

```python
class CurriculumWrapper:
    """
    í•™ìŠµ ì§„í–‰ì— ë”°ë¼ perturbation ê°•ë„ ì¦ê°€
    """
    def __init__(self, env, initial_force=10.0, final_force=100.0):
        self.env = env
        self.initial_force = initial_force
        self.final_force = final_force
        self.progress = 0.0  # 0 to 1

    def update_curriculum(self, timestep, total_timesteps):
        self.progress = timestep / total_timesteps
        current_force = (self.initial_force +
                        (self.final_force - self.initial_force) * self.progress)
        return current_force
```

### 2. **Asymmetric Actor-Critic**

í•™ìŠµ ì‹œì—ë§Œ privileged information ì‚¬ìš©:

```python
# Actor (deployment): ì‹¤ì œ ê´€ì¸¡ê°’ë§Œ
obs_actor = [joint_pos, joint_vel, imu, ...]

# Critic (training): privileged info í¬í•¨
obs_critic = [joint_pos, joint_vel, imu, ...,
              terrain_height, friction_coef, external_forces]
```

### 3. **Recovery Policy**

ë„˜ì–´ì§„ í›„ ì¼ì–´ë‚˜ê¸° í•™ìŠµ:

```yaml
task_factory:
  params:
    default_dataset_conf:
        task: [walk, run, getup, rollover]  # recovery ë™ì‘ í¬í•¨
```

---

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ

| ê¸°ë²• | ì™¸ë ¥ ëŒ€ì‘ ëŠ¥ë ¥ | í•™ìŠµ ì‹œê°„ | êµ¬í˜„ ë‚œì´ë„ |
|------|---------------|-----------|------------|
| **Perturbation** | +300% | +50% | ì‰¬ì›€ â­â­ |
| **Domain Randomization** | +150% | +30% | ì‰¬ì›€ â­â­ |
| **Observation Noise** | +100% | +20% | ì‰¬ì›€ â­ |
| **Curriculum** | +200% | +10% | ì¤‘ê°„ â­â­â­ |
| **Asymmetric AC** | +250% | +40% | ì–´ë ¤ì›€ â­â­â­â­ |
| **Multi-task** | +180% | +100% | ì¤‘ê°„ â­â­â­ |

**ëª¨ë‘ ì ìš© ì‹œ ì˜ˆìƒ íš¨ê³¼:**
- ì™¸ë ¥ ëŒ€ì‘: í˜„ì¬ ëŒ€ë¹„ **5-10ë°° í–¥ìƒ**
- Episode ê¸¸ì´: 1000 â†’ 5000+ steps
- Recovery rate: 10% â†’ 80%+

---

## ğŸš€ ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš

### Phase 1: Perturbation Training (1ì£¼)

```bash
# 1. Wrapper êµ¬í˜„
# 2. conf.yaml ì‘ì„±
# 3. í•™ìŠµ ì‹œì‘ (200M timesteps, ~2-3ì¼)
python custom/training/unitreeh1_robust/train.py
```

**ëª©í‘œ:**
- ì™¸ë ¥ 100Nê¹Œì§€ ëŒ€ì‘
- Episode length 3000+ steps

### Phase 2: Multi-task + DR (1ì£¼)

```yaml
# ë‹¤ì–‘í•œ ë™ì‘ + Domain Randomization
task: [walk, run, pace, trot, jump]
mass_range: 0.3
friction_range: 0.4
```

**ëª©í‘œ:**
- ë‹¤ì–‘í•œ ì§€í˜•/ì¡°ê±´ì—ì„œ ì•ˆì •
- Sim-to-real ì¤€ë¹„

### Phase 3: Advanced Techniques (2-4ì£¼)

```python
# Curriculum + Asymmetric + Recovery
# ASE/PHC ë…¼ë¬¸ êµ¬í˜„
```

**ëª©í‘œ:**
- State-of-the-art robustness
- ì‹¤ì œ ë¡œë´‡ ì ìš© ê°€ëŠ¥ ìˆ˜ì¤€

---

## ğŸ”— MuJoCo/MJX ë¦¬ì†ŒìŠ¤

### ê³µì‹ ë¬¸ì„œ:
- **MuJoCo**: https://mujoco.readthedocs.io/
- **MJX**: https://mujoco.readthedocs.io/en/stable/mjx.html
- **LocoMuJoCo**: https://loco-mujoco.readthedocs.io/

### ì°¸ê³  êµ¬í˜„:
- **Brax** (MJX ê¸°ë°˜ RL): https://github.com/google/brax
- **MJX Examples**: https://github.com/google-deepmind/mujoco/tree/main/mjx
- **LocoMuJoCo Examples**: `/home/tinman/loco-mujoco/examples/`

### ë…¼ë¬¸ ì½”ë“œ (MuJoCo ê¸°ë°˜):
- **ASE**: https://github.com/nv-tlabs/ASE
- **PHC**: https://github.com/ZhengyiLuo/PHC
- **AMP**: https://github.com/xbpeng/DeepMimic

---

## ğŸ’¡ ê²°ë¡ 

**MuJoCo/MJXë¡œ Isaac Gym ìˆ˜ì¤€ì˜ robustness ë‹¬ì„± ê°€ëŠ¥!**

âœ… **ì¥ì :**
- ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤
- LocoMuJoCo 22,000+ mocap í™œìš©
- JAX ìë™ ë¯¸ë¶„ + GPU ë³‘ë ¬í™”
- ìµœì‹  ì—°êµ¬ ëŒ€ë¶€ë¶„ ì§€ì›

âœ… **ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥:**
- ìœ„ wrapper ì½”ë“œ ë³µì‚¬
- conf.yaml ì‘ì„±
- í•™ìŠµ ì‹œì‘!

âœ… **í™•ì¥ì„±:**
- ASE, PHC ë“± êµ¬í˜„ ê°€ëŠ¥
- ì‹¤ì œ ë¡œë´‡ê¹Œì§€ ì „ì´ ê°€ëŠ¥
- ì—°êµ¬ ë…¼ë¬¸ ìˆ˜ì¤€ ê²°ê³¼ ë‹¬ì„± ê°€ëŠ¥

**ë‹¤ìŒ ë‹¨ê³„:** Perturbation wrapper êµ¬í˜„í•˜ê³  í•™ìŠµ ì‹œì‘í•˜ë©´ ë©ë‹ˆë‹¤!
