# LocoMuJoCo ì„¤ì¹˜ ë° ìµœì í™” ìš”ì•½

## ğŸ“¦ ì„¤ì¹˜ ì™„ë£Œ ë‚´ì—­

### 1. í™˜ê²½ ì •ë³´
- **í™˜ê²½ ì´ë¦„**: `loco-mujoco`
- **Python ë²„ì „**: 3.11.14
- **íŒ¨í‚¤ì§€ ê´€ë¦¬**: Conda
- **loco-mujoco ë²„ì „**: 1.0.1 (editable mode)
- **JAX ë²„ì „**: 0.7.1 with CUDA 12 support
- **GPU**: NVIDIA GeForce RTX 3070 (8GB VRAM)
- **CUDA ë²„ì „**: 13.0 (í˜¸í™˜)

### 2. ì„¤ì¹˜ëœ ì£¼ìš” íŒ¨í‚¤ì§€
- **MuJoCo**: 3.2.7
- **MuJoCo MJX**: 3.2.7 (JAX ë³‘ë ¬ í™˜ê²½)
- **JAX/JAXlib**: 0.7.1
- **JAX CUDA Plugin**: 0.7.1
- **Gymnasium**: 1.2.1
- **Flax**: 0.12.0 (ì‹ ê²½ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬)
- **Optax**: 0.2.6 (ìµœì í™”)
- **ê¸°íƒ€**: hydra-core, wandb í˜¸í™˜ ì¤€ë¹„

---

## ğŸš€ í™˜ê²½ ì‚¬ìš©ë²•

### í™˜ê²½ í™œì„±í™”
```bash
conda activate loco-mujoco
```

### í™˜ê²½ ë¹„í™œì„±í™”
```bash
conda deactivate
```

### Python ì‹¤í–‰ (í™˜ê²½ í™œì„±í™” í›„)
```bash
python your_script.py
```

---

## âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼

### 1. ê¸°ë³¸ í™˜ê²½ í…ŒìŠ¤íŠ¸ âœ“
- **UnitreeH1 í™˜ê²½**: ì •ìƒ ì‘ë™
- **Action dim**: 19
- **Observation dim**: 49
- **Dataset ìë™ ë‹¤ìš´ë¡œë“œ**: ì„±ê³µ

### 2. MJX GPU ê°€ì† í…ŒìŠ¤íŠ¸ âœ“
- **ë³‘ë ¬ í™˜ê²½ ìˆ˜**: 64ê°œ
- **ì´ ìŠ¤í… ìˆ˜**: 64,000 steps
- **ì‹¤í–‰ ì‹œê°„**: 6.07ì´ˆ
- **ì„±ëŠ¥**: 10,551 steps/sec
- **FPS per env**: 164.9
- **GPU ì¸ì‹**: CudaDevice(id=0) âœ“

### 3. ë‹¤ì¤‘ í™˜ê²½ í…ŒìŠ¤íŠ¸ âœ“
| í™˜ê²½ | ìƒíƒœ | Action Dim | Obs Dim |
|------|------|------------|---------|
| UnitreeH1 (Humanoid) | âœ“ PASSED | 19 | 49 |
| UnitreeG1 (Humanoid) | âœ“ PASSED | 23 | 57 |
| Atlas (Humanoid) | âœ“ PASSED | 27 | 65 |

---

## ğŸ¯ VRAM ìµœì í™” ê²°ê³¼

### RTX 3070 (8GB) ìµœì  ì„¤ì •

#### í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
| N_Envs | VRAM ì‚¬ìš©ëŸ‰ | Steps/sec | FPS/env | íš¨ìœ¨ì„± |
|--------|-------------|-----------|---------|--------|
| 16 | 6240 MB | 2,913 | 182.1 | â˜…â˜…â˜†â˜†â˜† |
| 32 | 6240 MB | 5,865 | 183.3 | â˜…â˜…â˜…â˜†â˜† |
| 64 | 6240 MB | 10,324 | 161.3 | â˜…â˜…â˜…â˜…â˜† |
| 128 | 6240 MB | 19,718 | 154.1 | â˜…â˜…â˜…â˜…â˜† |
| 256 | 6240 MB | 34,181 | 133.5 | â˜…â˜…â˜…â˜…â˜… |
| **512** | **6240 MB** | **52,353** | **102.3** | **â˜…â˜…â˜…â˜…â˜…** |

### ê¶Œì¥ ì„¤ì •

#### 1. ìµœëŒ€ ì„±ëŠ¥ ìš°ì„  (ê°œë°œ/ì—°êµ¬ìš©)
```python
num_envs = 512
num_minibatches = 64  # 512 / 8
vram_usage = 76.2%    # 6240 MB / 8192 MB
```

#### 2. ì•ˆì •ì„± ìš°ì„  (ì¥ì‹œê°„ í•™ìŠµ)
```python
num_envs = 256
num_minibatches = 32  # 256 / 8
vram_usage = 76.2%
```

#### 3. ë©”ëª¨ë¦¬ ì—¬ìœ  í•„ìš” (ëŒ€í˜• ëª¨ë¸/ë””ë²„ê¹…)
```python
num_envs = 128
num_minibatches = 16  # 128 / 8
vram_usage = 76.2%
```

### Mini-batch í¬ê¸° ê¶Œì¥ì‚¬í•­
- **ì¼ë°˜ ê·œì¹™**: `num_minibatches = num_envs / 4 ~ num_envs / 8`
- **PPO**: mini_batch_size = 16-64
- **GAIL/AMP**: mini_batch_size = 16-64
- **í° ëª¨ë¸ ì‚¬ìš© ì‹œ**: ë” ì‘ì€ ë°°ì¹˜ ì‚¬ìš©

---

## ğŸ“š ì˜ˆì œ ì‹¤í–‰ ê°€ì´ë“œ

### 1. ê¸°ë³¸ í™˜ê²½ í…ŒìŠ¤íŠ¸
```bash
conda activate loco-mujoco
python test_basic_env.py
```

### 2. MJX GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
```bash
python test_mjx_gpu.py
```

### 3. VRAM ìµœì í™” í…ŒìŠ¤íŠ¸
```bash
python test_vram_optimization.py
```

### 4. ë‹¤ì¤‘ í™˜ê²½ í…ŒìŠ¤íŠ¸
```bash
python test_multiple_envs.py
```

### 5. PPO í•™ìŠµ ì˜ˆì œ (ê³µì‹)
```bash
cd examples/training_examples/jax_rl
python experiment.py
```
- **ì˜ˆìƒ í•™ìŠµ ì‹œê°„**: ~20ë¶„ (RTX 3080 Ti ê¸°ì¤€)
- **RTX 3070 ì˜ˆìƒ**: ~25-30ë¶„
- **ì´ ìŠ¤í…**: 100M steps
- **í™˜ê²½**: UnitreeGo2
- **ì•Œê³ ë¦¬ì¦˜**: PPO

### 6. ë°ì´í„°ì…‹ ì‹œê°í™” (ë Œë”ë§ í•„ìš”)
```bash
cd examples/tutorials
python 00_replay_datasets.py
```

---

## ğŸ”§ ì¶”ê°€ ì„¤ì • (ì„ íƒì‚¬í•­)

### MyoSkeleton í™˜ê²½ ì‚¬ìš©
```bash
conda activate loco-mujoco
loco-mujoco-myomodel-init
```

### ë°ì´í„°ì…‹ ë¡œë”© ì†ë„ ê°œì„  (ìºì‹œ ì„¤ì •)
```bash
loco-mujoco-set-all-caches --path "$HOME/.loco-mujoco-caches"
```

### AMASS ë°ì´í„°ì…‹ ì‚¬ìš©
[loco_mujoco/smpl/README.md](loco_mujoco/smpl) ì°¸ì¡°

---

## ğŸ’¡ í•™ìŠµ ì„¤ì • ìµœì í™” íŒ

### RTX 3070 (8GB) ê¶Œì¥ ì„¤ì •

#### conf.yaml ìˆ˜ì • ì˜ˆì‹œ
```yaml
experiment:
  num_envs: 512          # VRAM ìµœì í™” ê²°ê³¼ ê¸°ë°˜
  num_minibatches: 64    # 512 / 8
  num_steps: 50          # ê¸°ë³¸ê°’ ìœ ì§€
  hidden_layers: [512, 256]  # ëª¨ë¸ í¬ê¸° ì¡°ì • ê°€ëŠ¥
  lr: 1e-4
  total_timesteps: 10e7
```

#### ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì¡°ì •
```yaml
experiment:
  num_envs: 256          # í™˜ê²½ ìˆ˜ ì¤„ì´ê¸°
  num_minibatches: 32
  hidden_layers: [256, 128]  # ëª¨ë¸ í¬ê¸° ì¤„ì´ê¸°
```

### XLA ìµœì í™” í”Œë˜ê·¸
ì½”ë“œì— ì´ë¯¸ ì ìš©ë¨:
```python
os.environ['XLA_FLAGS'] = '--xla_gpu_triton_gemm_any=True'
```

---

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìš”ì•½

### RTX 3070 ì„±ëŠ¥
- **ë³‘ë ¬ í™˜ê²½ 512ê°œ**: 52,353 steps/sec
- **íš¨ìœ¨ì„±**: 8.39 steps/sec/MB VRAM
- **VRAM ì‚¬ìš©ë¥ **: 76.2% (6240 MB / 8192 MB)
- **ê°œë³„ í™˜ê²½ FPS**: 102.3 FPS

### ì˜ˆìƒ í•™ìŠµ ì‹œê°„ (100M steps ê¸°ì¤€)
```
100,000,000 steps / 52,353 steps/sec â‰ˆ 1,910 ì´ˆ â‰ˆ 32ë¶„
```
(ì‹¤ì œë¡œëŠ” ë„¤íŠ¸ì›Œí¬ ì—…ë°ì´íŠ¸ ì‹œê°„ ì¶”ê°€ë¡œ ë” ì†Œìš”)

---

## ğŸ› ë¬¸ì œ í•´ê²°

### VRAM ë¶€ì¡± ì—ëŸ¬
1. `num_envs` ì¤„ì´ê¸°: 512 â†’ 256 â†’ 128
2. `hidden_layers` ì¤„ì´ê¸°: [512, 256] â†’ [256, 128]
3. `num_minibatches` ë¹„ë¡€í•´ì„œ ì¤„ì´ê¸°

### JAX/CUDA ì˜¤ë¥˜
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# JAX ì¬ì„¤ì¹˜
pip install --upgrade "jax[cuda12]"
```

### ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```bash
# ìºì‹œ ì‚­ì œ í›„ ì¬ì‹œë„
rm -rf ~/.cache/huggingface
python your_script.py
```

---

## ğŸ“– ì¶”ê°€ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LocoMuJoCo Documentation](https://loco-mujoco.readthedocs.io/)
- [GitHub Repository](https://github.com/robfiras/loco-mujoco)
- [Discord Community](https://discord.gg/gEqR3xCVdn)

### ì˜ˆì œ ìœ„ì¹˜
- **íŠœí† ë¦¬ì–¼**: [examples/tutorials/](examples/tutorials/)
- **í•™ìŠµ ì˜ˆì œ**: [examples/training_examples/](examples/training_examples/)
- **ê¶¤ì  ìƒì„±**: [examples/trajectory_generation/](examples/trajectory_generation/)

### ì£¼ìš” ì•Œê³ ë¦¬ì¦˜
- **PPO**: [examples/training_examples/jax_rl/](examples/training_examples/jax_rl/)
- **GAIL**: [examples/training_examples/jax_gail/](examples/training_examples/jax_gail/)
- **AMP**: [examples/training_examples/jax_amp/](examples/training_examples/jax_amp/)
- **DeepMimic**: [examples/training_examples/jax_rl_mimic/](examples/training_examples/jax_rl_mimic/)

---

## âœ¨ ë‹¤ìŒ ë‹¨ê³„

1. **ê¸°ë³¸ ì˜ˆì œ ì‹¤í–‰**: `test_mjx_gpu.py`ë¡œ ì„¤ì • í™•ì¸
2. **íŠœí† ë¦¬ì–¼ í•™ìŠµ**: `examples/tutorials/` ìˆœì„œëŒ€ë¡œ ì‹¤ìŠµ
3. **PPO í•™ìŠµ ì‹œì‘**: `examples/training_examples/jax_rl/experiment.py`
4. **ì„¤ì • ìµœì í™”**: ë³¸ì¸ GPUì— ë§ê²Œ `num_envs`, `num_minibatches` ì¡°ì •
5. **ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜ ì‹¤í—˜**: GAIL, AMP, DeepMimic ì‹œë„

---

**ì„¤ì¹˜ ì™„ë£Œ!** ğŸ‰

ì´ì œ loco-mujocoë¡œ ë¡œë´‡ í•™ìŠµì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!
